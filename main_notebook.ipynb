{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krafthack 7-8. february 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 00:07:57.280171: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-08 00:07:57.280360: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import optimizers, Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Activation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.preprocessing import get_timeslots, get_temporal_lookback_features, get_temporal_lookback_df, add_hour_feature, add_seconds_operational"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet('data/input_dataset-2.parquet')\n",
    "df_test = pd.read_parquet('data/prediction_input.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant features\n",
    "cols_keep = list(df_test.columns) + [f'Bolt_{i}_Tensile' for i in range(1,7)]\n",
    "df_train = df_train[cols_keep]\n",
    "\n",
    "# Remove rows that contain any missing values\n",
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both datasets before doing feature engineering\n",
    "df_full = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.tail().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Log-transform\n",
    "- Signal-analysis (derivatives, Fourier transform, power, etc)\n",
    "- Temporal features (day, month, holiday, etc)\n",
    "- Sequencing\n",
    "- Onehhot encoding of categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = add_hour_feature(df_full)\n",
    "df_full = add_seconds_operational(df_full)\n",
    "df_full['time_weekday'] = df_full.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.tail().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode_as_dummy(df):\n",
    "    # Make \"mode\" into dummy variable\n",
    "    y = pd.get_dummies(df[\"mode\"], prefix=\"Mode\")\n",
    "    df = df.join(y)\n",
    "    df.drop(\"mode\", inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "df_full = get_mode_as_dummy(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get look-back features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe change this for some aggregated features instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'Unit_4_Power',\n",
    "    'Unit_4_Reactive Power',\n",
    "    'Turbine_Guide Vane Opening',\n",
    "    'Turbine_Pressure Drafttube',\n",
    "    'Turbine_Pressure Spiral Casing',\n",
    "    'Turbine_Rotational Speed'\n",
    "    ]\n",
    "\n",
    "\n",
    "df_timeslots_list = get_timeslots(df_full)\n",
    "df_full_with_lookback = get_temporal_lookback_df(df_timeslots_list, cols=columns, window_size=30, steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train-validate-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new = df_full_with_lookback[df_train.index[0]:df_train.index[-1]].dropna()\n",
    "df_test_new  = df_full_with_lookback[df_test.index[0]:df_test.index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert previous y_value\n",
    "labels = [f\"Bolt_{i}_Tensile\" for i in range(1,7)]\n",
    "labels_prev = [f\"Bolt_{i}_Tensile_prev\" for i in range(1,7)]\n",
    "\n",
    "df_train_new[labels_prev] = df_train_new[labels].shift(1)\n",
    "df_train_new.loc[df_train_new.index[0], labels_prev] = df_train_new.loc[df_train_new.index[1], labels_prev]\n",
    "\n",
    "df_test_new[labels_prev] = np.nan\n",
    "df_test_new.loc[df_test_new.index[0], labels_prev] = df_train_new.loc[df_train_new.index[-1], labels_prev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_train_new: {df_train_new.shape}\")\n",
    "print(f\"df_test: {df_test.shape}\")\n",
    "print(f\"df_test_new: {df_test_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_SPLIT = 0.7\n",
    "\n",
    "X_train = df_train_new.drop(labels, axis=1)\n",
    "X_train_train = X_train[:int(PCT_SPLIT*len(X_train))]\n",
    "X_train_val = X_train[int(PCT_SPLIT*len(X_train)):]\n",
    "\n",
    "X_test = df_test_new.drop(labels, axis=1)\n",
    "\n",
    "y_train = df_train_new[labels]\n",
    "y_train_train = y_train[:int(PCT_SPLIT*len(y_train))]\n",
    "y_train_val = y_train[int(PCT_SPLIT*len(y_train)):]\n",
    "\n",
    "y_test = df_test_new[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:        (1748596, 53)\n",
      "X_train_train:  (1224017, 53)\n",
      "X_train_val:    (524579, 53)\n",
      "X_test:         (226364, 53)\n",
      "\n",
      "y_train:        (1748596, 6)\n",
      "y_train_train:  (1224017, 6)\n",
      "y_train_val:    (524579, 6)\n",
      "y_test:         (226364, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train:        {X_train.shape}\")\n",
    "print(f\"X_train_train:  {X_train_train.shape}\")\n",
    "print(f\"X_train_val:    {X_train_val.shape}\")\n",
    "print(f\"X_test:         {X_test.shape}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"y_train:        {y_train.shape}\")\n",
    "print(f\"y_train_train:  {y_train_train.shape}\")\n",
    "print(f\"y_train_val:    {y_train_val.shape}\")\n",
    "print(f\"y_test:         {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('data/X_train.pkl')\n",
    "X_train_train.to_pickle('data/X_train_train.pkl')\n",
    "X_train_val.to_pickle('data/X_train_val.pkl')\n",
    "X_test.to_pickle('data/X_test.pkl')\n",
    "y_train.to_pickle('data/y_train.pkl')\n",
    "y_train_train.to_pickle('data/y_train_train.pkl')\n",
    "y_train_val.to_pickle('data/y_train_val.pkl')\n",
    "y_test.to_pickle('data/y_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('data/X_train.pkl')\n",
    "X_train_train = pd.read_pickle('data/X_train_train.pkl')\n",
    "X_train_val = pd.read_pickle('data/X_train_val.pkl')\n",
    "X_test = pd.read_pickle('data/X_test.pkl')\n",
    "y_train = pd.read_pickle('data/y_train.pkl')\n",
    "y_train_train = pd.read_pickle('data/y_train_train.pkl')\n",
    "y_train_val = pd.read_pickle('data/y_train_val.pkl')\n",
    "y_test = pd.read_pickle('data/y_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler_X.fit_transform(X_train_train),\n",
    "    index = X_train_train.index,\n",
    "    columns = X_train_train.columns\n",
    "    )\n",
    "X_train_val_scaled = pd.DataFrame(\n",
    "    scaler_X.transform(X_train_val),\n",
    "    index = X_train_val.index,\n",
    "    columns = X_train_val.columns\n",
    "    )\n",
    "y_train_scaled = pd.DataFrame(\n",
    "    scaler_y.fit_transform(y_train_train),\n",
    "    index = y_train_train.index,\n",
    "    columns = y_train_train.columns\n",
    "    )\n",
    "y_train_val_scaled = pd.DataFrame(\n",
    "    scaler_y.transform(y_train_val),\n",
    "    index = y_train_val.index,\n",
    "    columns = y_train_val.columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee59f258e76436f86931d2e626596f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models['linreg'] = [LinearRegression() for i in range(2)]\n",
    "# models['linreg'] = [LinearRegression() for i in range(6)]\n",
    "\n",
    "for i, model in tqdm(enumerate(models['linreg']), total=len(models['linreg'])):\n",
    "    model.fit(X_train_scaled, y_train_scaled[f\"Bolt_{i+1}_Tensile\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models['rndforest'] = [RandomForestRegressor(\n",
    "#     max_depth=4,\n",
    "#     n_estimators=100,\n",
    "#     criterion=\"absolute_error\",\n",
    "#     max_features=4)\n",
    "#     for i in range(6)]\n",
    "\n",
    "# for i, model in tqdm(enumerate(models['rndforest']), total=6):\n",
    "#     model.fit(X_train_train, y_train_train[f\"Bolt_{i+1}_Tensile\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['xgboost'] = [XGBRegressor(\n",
    "    booster=\"gbtree\",\n",
    "    learning_rate=0.2,\n",
    "    gamma=0.1,\n",
    "    max_depth=6,\n",
    "    eval_metric=\"mae\")\n",
    "    for i in range(6)]\n",
    "\n",
    "for i, model in tqdm(enumerate(models['xgboost']), total=6):\n",
    "    model.fit(X_train_scaled, y_train_scaled[f\"Bolt_{i+1}_Tensile\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "- [Special methods for time-series data](https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "- [Sklearn](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "- [Nevergrad](https://facebookresearch.github.io/nevergrad/)\n",
    "- [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and score\n",
    "- Good metrics for temporal data?\n",
    "- Depends on competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_inf = [i for i, arr in enumerate(X_train_val_scaled) if not np.isfinite(arr).all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val.iloc[idx_inf[0]-2:idx_inf[0]+2, -6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_val_scaled[idx[0]-2:idx[0]+2, -6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28120/2559068575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# For each model type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "labels = [f\"Bolt_{i}_Tensile\" for i in range(1,2)]\n",
    "# labels = [f\"Bolt_{i}_Tensile\" for i in range(1,7)]\n",
    "y_preds = {}\n",
    "\n",
    "for model_name, model in tqdm(models.items(), total=len(models)):\n",
    "    # For each model type\n",
    "    y_preds[model_name] = {}\n",
    "    for model_i, label in tqdm(enumerate(labels), total=len(labels)):\n",
    "        # For each sub-model specialized for a unique label column\n",
    "        y_preds[model_name][label] = []\n",
    "        for idx, (_, row) in enumerate(X_train_val_scaled.iterrows()):\n",
    "            # For each row, predict and forward-fill predicted value to next row\n",
    "            y_hat = model[model_i].predict(row.to_frame().T)[0]\n",
    "            y_preds[model_name][label].append(y_hat)\n",
    "            if idx < len(X_train_val_scaled):\n",
    "                X_train_val_scaled.iloc[idx+1, label+'_prev'] = y_hat\n",
    "\n",
    "    y_preds[model_name] = pd.DataFrame(y_preds[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model explanation\n",
    "- Explainable model ([interpretml](https://github.com/interpretml/interpret))\n",
    "- Certainty score\n",
    "- [LIME](https://github.com/marcotcr/lime)\n",
    "- [SHAP](https://github.com/slundberg/shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "- Pipeline for deploying model\n",
    "- Host model in e.g. Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
