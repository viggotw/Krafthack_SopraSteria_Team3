{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krafthack 7-8. february 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import optimizers, Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Activation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.preprocessing import get_timeslots, get_temporal_lookback_features, get_temporal_lookback_df, add_hour_feature, add_seconds_operational"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet('data/input_dataset-2.parquet')\n",
    "df_test = pd.read_parquet('data/prediction_input.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant features\n",
    "cols_keep = list(df_test.columns) + [f'Bolt_{i}_Tensile' for i in range(1,7)]\n",
    "df_train = df_train[cols_keep]\n",
    "\n",
    "# Remove rows that contain any missing values\n",
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both datasets before doing feature engineering\n",
    "df_full = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.tail().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Log-transform\n",
    "- Signal-analysis (derivatives, Fourier transform, power, etc)\n",
    "- Temporal features (day, month, holiday, etc)\n",
    "- Sequencing\n",
    "- Onehhot encoding of categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = add_hour_feature(df_full)\n",
    "df_full = add_seconds_operational(df_full)\n",
    "df_full['time_weekday'] = df_full.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.tail().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode_as_dummy(df):\n",
    "    # Make \"mode\" into dummy variable\n",
    "    y = pd.get_dummies(df[\"mode\"], prefix=\"Mode\")\n",
    "    df = df.join(y)\n",
    "    df.drop(\"mode\", inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "df_full = get_mode_as_dummy(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get look-back features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe change this for some aggregated features instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [\n",
    "#     'Unit_4_Power',\n",
    "#     'Unit_4_Reactive Power',\n",
    "#     'Turbine_Guide Vane Opening',\n",
    "#     'Turbine_Pressure Drafttube',\n",
    "#     'Turbine_Pressure Spiral Casing',\n",
    "#     'Turbine_Rotational Speed'\n",
    "#     ]\n",
    "\n",
    "\n",
    "# df_timeslots_list = get_timeslots(df_full)\n",
    "# df_full_with_lookback = get_temporal_lookback_df(df_timeslots_list, cols=columns, window_size=30, steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train-validate-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_new = df_full_with_lookback[df_train.index[0]:df_train.index[-1]].dropna()\n",
    "# df_test_new  = df_full_with_lookback[df_test.index[0]:df_test.index[-1]]\n",
    "\n",
    "df_train_new = df_full[df_train.index[0]:df_train.index[-1]].dropna()\n",
    "df_test_new  = df_full[df_test.index[0]:df_test.index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new['1971-01-31 06:47:00':].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_train_new: {df_train_new.shape}\")\n",
    "print(f\"df_test: {df_test.shape}\")\n",
    "print(f\"df_test_new: {df_test_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_SPLIT = 0.7\n",
    "labels = [f\"Bolt_{i}_Tensile\" for i in range(1,7)]\n",
    "\n",
    "X_train_full = df_train_new.drop(labels, axis=1)  # Official test set\n",
    "y_train_full = df_train_new[labels]  # Official test labels\n",
    "\n",
    "X_test_full = df_test_new.drop(labels, axis=1)  # Official test set\n",
    "\n",
    "X_train_train = X_train_full[:int(PCT_SPLIT*len(X_train_full))]  # Private test set\n",
    "y_train_train = y_train_full[:int(PCT_SPLIT*len(y_train_full))]  # Private test labels\n",
    "X_train_val = X_train_full[int(PCT_SPLIT*len(X_train_full)):]  # Private validation set\n",
    "y_train_val = y_train_full[int(PCT_SPLIT*len(y_train_full)):]  # Private validation labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train_full:   {X_train_full.shape}\")\n",
    "print(f\"y_train_full:   {y_train_full.shape}\")\n",
    "print(f\"X_test_full:    {X_test_full.shape}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"X_train_train:  {X_train_train.shape}\")\n",
    "print(f\"y_train_train:  {y_train_train.shape}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"y_train_val:    {y_train_val.shape}\")\n",
    "print(f\"X_train_val:    {X_train_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.to_pickle('data/X_train_full.pkl')\n",
    "y_train_full.to_pickle('data/y_train_full.pkl')\n",
    "\n",
    "X_test_full.to_pickle('data/X_test_full.pkl')\n",
    "\n",
    "X_train_train.to_pickle('data/X_train_train.pkl')\n",
    "y_train_train.to_pickle('data/y_train_train.pkl')\n",
    "\n",
    "X_train_val.to_pickle('data/X_train_val.pkl')\n",
    "y_train_val.to_pickle('data/y_train_val.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.read_pickle('data/X_train_full.pkl')\n",
    "y_train_full = pd.read_pickle('data/y_train_full.pkl')\n",
    "\n",
    "X_test_full = pd.read_pickle('data/X_test_full.pkl')\n",
    "\n",
    "X_train_train = pd.read_pickle('data/X_train_train.pkl')\n",
    "y_train_train = pd.read_pickle('data/y_train_train.pkl')\n",
    "\n",
    "X_train_val = pd.read_pickle('data/X_train_val.pkl')\n",
    "y_train_val = pd.read_pickle('data/y_train_val.pkl')\n",
    "\n",
    "labels = [f\"Bolt_{i}_Tensile\" for i in range(1,7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler_X.fit_transform(X_train_train),\n",
    "    index = X_train_train.index,\n",
    "    columns = X_train_train.columns\n",
    "    )\n",
    "X_train_val_scaled = pd.DataFrame(\n",
    "    scaler_X.transform(X_train_val),\n",
    "    index = X_train_val.index,\n",
    "    columns = X_train_val.columns\n",
    "    )\n",
    "y_train_scaled = pd.DataFrame(\n",
    "    scaler_y.fit_transform(y_train_train),\n",
    "    index = y_train_train.index,\n",
    "    columns = y_train_train.columns\n",
    "    )\n",
    "y_train_val_scaled = pd.DataFrame(\n",
    "    scaler_y.transform(y_train_val),\n",
    "    index = y_train_val.index,\n",
    "    columns = y_train_val.columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "model_types = {}\n",
    "model_configs = {}\n",
    "model_fit_config = {}\n",
    "\n",
    "def train_model(models, model_type, model_config, model_fit_config, model_name, labels, X, y):\n",
    "    models[model_name] = {label: model_type(**model_config) for label in labels}\n",
    "\n",
    "    for label in tqdm(labels):\n",
    "        models[model_name][label].fit(X, y[label], **model_fit_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'linreg'\n",
    "model_types[MODEL_NAME] = LinearRegression\n",
    "model_configs[MODEL_NAME] = {}\n",
    "model_fit_config[MODEL_NAME] = {}\n",
    "\n",
    "train_model(\n",
    "    models,\n",
    "    model_type=model_types[MODEL_NAME],\n",
    "    model_config=model_configs[MODEL_NAME],\n",
    "    model_fit_config=model_fit_config[MODEL_NAME],\n",
    "    model_name=MODEL_NAME,\n",
    "    labels=labels,\n",
    "    X=X_train_scaled,\n",
    "    y=y_train_scaled\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'xgboost'\n",
    "model_types[MODEL_NAME]=XGBRegressor\n",
    "model_configs[MODEL_NAME] = dict(\n",
    "    booster=\"gbtree\",\n",
    "    learning_rate=0.2,\n",
    "    gamma=0.1,\n",
    "    max_depth=6,\n",
    "    eval_metric=\"mae\")\n",
    "model_fit_config[MODEL_NAME] = {}\n",
    "\n",
    "train_model(\n",
    "    models,\n",
    "    model_type=model_types[MODEL_NAME],\n",
    "    model_config=model_configs[MODEL_NAME],\n",
    "    model_fit_config=model_fit_config[MODEL_NAME],\n",
    "    model_name=MODEL_NAME,\n",
    "    labels=labels,\n",
    "    X=X_train_scaled,\n",
    "    y=y_train_scaled\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'catboost'\n",
    "model_types[MODEL_NAME]=CatBoostRegressor\n",
    "model_configs[MODEL_NAME] = dict(iterations=400)\n",
    "model_fit_config[MODEL_NAME] = dict(verbose=False)\n",
    "\n",
    "\n",
    "train_model(\n",
    "    models,\n",
    "    model_type=model_types[MODEL_NAME],\n",
    "    model_config=model_configs[MODEL_NAME],\n",
    "    model_fit_config=model_fit_config[MODEL_NAME],\n",
    "    model_name=MODEL_NAME,\n",
    "    labels=labels,\n",
    "    X=X_train_scaled,\n",
    "    y=y_train_scaled\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viggo's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleTrouble():\n",
    "    def __init__(self, model_seq, fit_params=None):\n",
    "        self.model_seq = model_seq\n",
    "        self.fit_params = fit_params\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_new = X.copy()\n",
    "        y_new = y.to_numpy()\n",
    "        for model, fit_param in tqdm(zip(self.model_seq, self.fit_params), total=len(self.model_seq)):\n",
    "            model.fit(X_new, y_new, **fit_param)\n",
    "            y_new = y_new - model.predict(X_new)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_hat = np.zeros(shape=(X.shape[0],))\n",
    "        for model in tqdm(self.model_seq, total=len(self.model_seq)):\n",
    "            y_hat = y_hat + model.predict(X)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_train\n",
    "# X_train_val\n",
    "# y_train_train\n",
    "# y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' on line 4 (2887999328.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_665/2887999328.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '[' on line 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "trouble2 = DoubleTrouble(\n",
    "    model_seq= [\n",
    "        Lasso(),\n",
    "        XGBRegressor(\n",
    "            booster=\"gbtree\",\n",
    "            learning_rate=0.2,\n",
    "            gamma=0.1,\n",
    "            max_depth=6,\n",
    "            eval_metric=\"mae\"\n",
    "        )\n",
    "    ],\n",
    "    fit_params=[\n",
    "        {},\n",
    "        {plot:True, verbose:False}\n",
    "    ]\n",
    ")\n",
    "\n",
    "trouble2.fit(X_train_train, y_train_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trouble2.predict(X_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(y_train_val.iloc[:,0], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "- [Special methods for time-series data](https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "- [Sklearn](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "- [Nevergrad](https://facebookresearch.github.io/nevergrad/)\n",
    "- [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [f\"Bolt_{i}_Tensile\" for i in range(1,7)]\n",
    "y_preds_scaled = {}\n",
    "y_preds = {}\n",
    "\n",
    "\n",
    "for model_name, model in tqdm(models.items(), total=len(models)):\n",
    "    # For each model type\n",
    "    y_preds[model_name] = {}\n",
    "    for label in tqdm(labels):\n",
    "        # For each sub-model specialized for a unique label column\n",
    "        y_preds[model_name][label] = model[label].predict(X_train_val_scaled)\n",
    "\n",
    "    y_preds_scaled[model_name] = pd.DataFrame(y_preds[model_name])\n",
    "    y_preds[model_name] = pd.DataFrame(scaler_y.inverse_transform(y_preds_scaled[model_name].to_numpy()),\n",
    "                                       index=y_preds_scaled[model_name].index,\n",
    "                                       columns=y_preds_scaled[model_name].columns\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions vs truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, len(y_preds), sharey=True, sharex=True, figsize=(20,10))\n",
    "fig.suptitle('Residuals', fontsize=16)\n",
    "for j, (model_name, y_hats) in tqdm(enumerate(y_preds.items()), total=len(y_preds)):\n",
    "    for i, col in tqdm(enumerate(y_hats.columns), total=y_hats.shape[1]):\n",
    "        axs[i,j].plot(y_hats[col] - y_train_val[col].to_numpy())\n",
    "        axs[i,j].set_title(f\"{model_name} {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "- Good metrics for temporal data?\n",
    "- Depends on competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = {}\n",
    "\n",
    "for model_name, model in y_preds.items():\n",
    "    score[model_name] = {}\n",
    "    \n",
    "    for label in labels:\n",
    "        score[model_name][label] = mape(y_train_val[label], y_preds[model_name][label])\n",
    "\n",
    "scores = pd.DataFrame(score).T\n",
    "scores.rename({x: f'MAPE {x}' for x in scores.columns}, axis=1)\n",
    "scores['Avg MAPE'] = scores.mean(axis=1)\n",
    "scores = scores.sort_values(by='Avg MAPE', ascending=True)\n",
    "BEST_MODEL = scores.index[0]\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Using the output of the first model as input to a second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model explanation\n",
    "- Explainable model ([interpretml](https://github.com/interpretml/interpret))\n",
    "- Certainty score\n",
    "- [LIME](https://github.com/marcotcr/lime)\n",
    "- [SHAP](https://github.com/slundberg/shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare competition submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on whole training seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale full training set\n",
    "scaler_X_full = StandardScaler()\n",
    "scaler_y_full = StandardScaler()\n",
    "\n",
    "X_train_full_scaled = scaler_X.fit_transform(X_train_full)\n",
    "X_test_full_scaled = scaler_X.transform(X_test_full)\n",
    "y_train_full_scaled = scaler_y_full.fit_transform(y_train_full)\n",
    "\n",
    "# Train on full training set\n",
    "train_model(\n",
    "    models,\n",
    "    model_type=model_types[MODEL_NAME],\n",
    "    model_config=model_configs[BEST_MODEL],\n",
    "    model_fit_config=model_fit_config[BEST_MODEL],\n",
    "    model_name=MODEL_NAME,\n",
    "    labels=labels,\n",
    "    X=X_train_scaled,\n",
    "    y=y_train_scaled\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_preds_scaled = {}\n",
    "y_final_preds = {}\n",
    "\n",
    "for label in tqdm(labels):\n",
    "    # For each sub-model specialized for a unique label column\n",
    "    y_final_preds_scaled[label] = models[BEST_MODEL][label].predict(X_test_full_scaled)\n",
    "\n",
    "y_final_preds_scaled = pd.DataFrame(y_final_preds_scaled)\n",
    "y_final_preds = pd.DataFrame(scaler_y.inverse_transform(y_final_preds_scaled.to_numpy()),\n",
    "                                    index=y_final_preds_scaled.index,\n",
    "                                    columns=y_final_preds_scaled.columns\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_preds.index = X_test_full.index\n",
    "y_final_preds.to_csv('submission.csv')\n",
    "\n",
    "y_final_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "- Pipeline for deploying model\n",
    "- Build API using FastAPI or Flask\n",
    "- Host model in e.g. Azure"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
